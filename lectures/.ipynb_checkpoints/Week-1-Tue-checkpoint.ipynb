{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ASTR-598, Winter 2018, Connolly & Ivezic, University of Washington\n",
    "https://github.com/dirac-institute/uw-astr598-w18/tree/master/lectures/Week-1-Tue.ipynb\n",
    "\n",
    "\n",
    "# Week 1, Tuesday: Introduction to Probability & Statistics. I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Resources for this notebook include:\n",
    "\n",
    "- [Textbook](http://press.princeton.edu/titles/10159.html) Chapters 3 and 4.  \n",
    "- [Gordon Richard's notebooks](https://github.com/gtrichards/PHYS_T480)\n",
    "- random contributions from a large number of colleagues (e.g. Jake VanderPlas, Mario Juric)\n",
    "\n",
    "##### Suggested supplemental background reading:\n",
    "\n",
    "[David Hogg: \"Data analysis recipes: Probability calculus for inference\"](https://arxiv.org/abs/1205.4446)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Learning goals for Week 1 (mostly based on Chapter 3 material): \n",
    "\n",
    "- Probability Rules (notation, definitions, conditional probability, Bayes Rule).\n",
    "- How do I robustly estimate location and scale parameters of a one-dimensional data set?  \n",
    "- Statistical distributions and how do we describe them? \n",
    "- Estimators, location and scale, sample vs. population, bias and scatter.\n",
    "- How do I use python to generate various statistical distributions, such as Cauchy, Laplace, etc.  \n",
    "- The Central Limit Theorem. \n",
    "- Robust estimators. \n",
    "- How do I robustly estimate parameters of a two-dimensional Gaussian?  \n",
    "- Bivariate and Multivariate Distribution Functions.  \n",
    "- How do we make a histogram and why? How do we choose optimal bin width?\n",
    "  Do histogram bins need to be same size?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notation\n",
    "\n",
    "First we need to go over some of the notation that the book uses.   \n",
    "\n",
    "$x$ is a scalar quantity, measured $N$ times\n",
    "\n",
    "$x_i$ is a single measurement with $i=1,...,N$\n",
    "\n",
    "$\\{x_i\\}$ refers to the set of all N measurements\n",
    "\n",
    "We are generally trying to *estimate* $h(x)$, the *true* distribution from which the values of $x$ are drawn. We will refer to $h(x)$ as the probability density (distribution) function or the \"pdf\" and $h(x)dx$ is the propobability of a value lying between $x$ and $x+dx$. \n",
    "\n",
    "While $h(x)$ is the \"true\" pdf (or **population** pdf).  What we *measure* from the data is the **empirical** pdf, which is denoted $f(x)$.  So, $f(x)$ is a *model* of $h(x)$.  In principle, with infinite data $f(x) \\rightarrow h(x)$, but in reality measurement errors keep this from being strictly true.\n",
    "\n",
    "If we are attempting to guess a *model* for $h(x)$, then the process is *parametric*.  With a model solution we can generate new data that should mimic what we measure.  If we are not attempting to guess a model, then the process is *nonparametic*.  That is we are just trying to describe the data that we see in the most compact manner that we can, but we are not trying to produce mock data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  We could summarize the goal of this class as an attempt to \n",
    "\n",
    "1) estimate $f(x)$ from some real (possibly multi-dimensional) data set, \n",
    "\n",
    "2) find a way to describe $f(x)$ and its uncertainty, \n",
    "\n",
    "3) compare it to models of $h(x)$, and then \n",
    "\n",
    "4) use the knowledge that we have gained to interpret new measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability\n",
    "\n",
    "The probability of $A$, $p(A)$, is the probability that some event will happen (say a coin toss), or if the process is continuous, the probability of $A$ falling in a certain range.  (N.B., Technically these two things are different and sometimes are indicated by $P$ and $p$, but we'll ignore that here).\n",
    "\n",
    "$p(A)$ must be positive definite for all $A$ and the sum/integral of the pdf must be unity.\n",
    "\n",
    "If we have two events, $A$ and $B$, the possible combinations are illustrated by the following figure:\n",
    "![Figure 3.1](http://www.astroml.org/_images/fig_prob_sum_1.png)\n",
    "\n",
    "$A \\cup B$ is the *union* of sets $A$ and $B$.\n",
    "\n",
    "$A \\cap B$ is the *intersection* of sets $A$ and $B$.\n",
    "\n",
    "The probability that *either* $A$ or $B$ will happen (which could include both) is the *union*, given by\n",
    "\n",
    "$$p(A \\cup B) = p(A) + p(B) - p(A \\cap B)$$\n",
    "\n",
    "The figure makes it clear why the last term is necessary.  Since $A$ and $B$ overlap, we are double-counting the region where *both* $A$ and $B$ happen, so we have to subtract this out.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The probability that *both* $A$ and $B$ will happen, $p(A \\cap B)$, is \n",
    "$$p(A \\cap B) = p(A|B)p(B) = p(B|A)p(A)$$\n",
    "\n",
    "where p(A|B) is the probability of A *given that* B is true and is called the *conditional probability*.  So the $|$ is short for \"given that\".\n",
    "\n",
    "The **law of total probability** says that\n",
    "\n",
    "$$p(A) = \\sum_ip(A|B_i)p(B_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "N.B.  Just to be annoying, different people use different notation and the following all mean the same thing\n",
    "\n",
    "$$p(A \\cap B) = p(A,B) = p(AB) = p(A \\,{\\rm and}\\, B)$$\n",
    "\n",
    "We will use the comma notation as in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "It is important to realize that the following is *always* true\n",
    "\n",
    "$$p(A,B) = p(A|B)p(B) = p(B|A)p(A)$$\n",
    "\n",
    "However, if $A$ and $B$ are independent, then \n",
    "\n",
    "$$p(A,B) = p(A)p(B)$$\n",
    "\n",
    "Let's look an example.\n",
    "\n",
    "If you have a bag with 5 marbles, 3 yellow and 2 blue and you want to know the probability of picking 2 yellow marbles in a row, that would be\n",
    "\n",
    "$$p(Y_1,Y_2) = p(Y_1)p(Y_2|Y_1).$$\n",
    "\n",
    "$p(Y_1) = \\frac{3}{5}$ since you have an equally likely chance of drawing any of the 5 marbles.\n",
    "\n",
    "If you did not put the first marble back in the back after drawing it (sampling *without* \"replacement\"), then the probability\n",
    "\n",
    "$p(Y_2|Y_1) = \\frac{2}{4}$, so that\n",
    "\n",
    "$$p(Y_1,Y_2) = \\frac{3}{5}\\frac{2}{4} = \\frac{3}{10}.$$\n",
    "\n",
    "But if you put the first marble back, then\n",
    "\n",
    "$p(Y_2|Y_1) = \\frac{3}{5} = p(Y_2)$, so that \n",
    "\n",
    "$$p(Y_1,Y_2) = \\frac{3}{5}\\frac{3}{5} = \\frac{9}{25}.$$\n",
    "\n",
    "In the first case $A$ and $B$ (or rather $Y_1$ and $Y_2$) are *not* independent, whereas in the second case they are.\n",
    "\n",
    "We say that two random variables, $A$ and $B$ are independent *if*\n",
    "\n",
    "$p(A,B) = p(A)p(B)$ (knowing $B$ does not give any information about $A$ and vice versa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is a more complicated example from \n",
    "[Jo Bovy's class at UToronto](http://astro.utoronto.ca/%7Ebovy/teaching.html)\n",
    "![Bovy_L1-StatMiniCourse_page21](figures/Bovy_L1-StatMiniCourse_page21.png)\n",
    "\n",
    "As illustrated, \n",
    "\n",
    "$$p(A \\,{\\rm or}\\, B|C) = p(A|C) + p(B|C) - p(A \\, {\\rm and}\\, B|C)$$ \n",
    "\n",
    "This illustration also explains why $$p(x|y)p(y) = p(y|x)p(x)$$ (used below),\n",
    "\n",
    "or in the notation of this figure: \n",
    "\n",
    "$$p(A \\, {\\rm and}\\, B) \\equiv p(A,B) = p(A|B)p(B) = p(B|A)p(A)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Need more help with this?  Try watching some Khan Academy videos and working through the exercises:\n",
    "[https://www.khanacademy.org/math/probability/probability-geometry](https://www.khanacademy.org/math/probability/probability-geometry)\n",
    "\n",
    "[https://www.khanacademy.org/math/precalculus/prob-comb](https://www.khanacademy.org/math/precalculus/prob-comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the following figure, we have a 2-D distribution in $x-y$ parameter space.  Here $x$ and $y$ are *not* independent as, once you pick a $y$, your values of $x$ are constrained.\n",
    "\n",
    "The *marginal* distributions are shown on the left and bottom sides of the left panel.  As the equation above says, this is just the integral along the $x$ direction for a given $y$ (left side panel) or the integral along the $y$ direction for a given $x$ (bottom panel).  \n",
    "\n",
    "The three panels on the right show the *conditional* probability (of $x$) for three $y$ values: $$p(x|y=y_0)$$  These are just \"slices\" through the 2-D distribution.\n",
    "\n",
    "![http://www.astroml.org/_images/fig_conditional_probability_1.png](http://www.astroml.org/_images/fig_conditional_probability_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes' Rule\n",
    "\n",
    "We have that \n",
    "\n",
    "$$p(x,y) = p(x|y)p(y) = p(y|x)p(x)$$\n",
    "\n",
    "We can define the *marginal probability* as\n",
    "\n",
    "$$p(x) = \\int p(x,y)dy,$$\n",
    "\n",
    "where marginal means essentially projecting on to one axis (integrating over the other axis, see the figure above).\n",
    "\n",
    "We can re-write this as\n",
    "\n",
    "$$p(x) = \\int p(x|y)p(y) dy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Since $$p(x|y)p(y) = p(y|x)p(x)$$ we can write that\n",
    "\n",
    "$$p(y|x) = \\frac{p(x|y)p(y)}{p(x)} = \\frac{p(x|y)p(y)}{\\int p(x|y)p(y) dy}$$\n",
    "which in words says that\n",
    "\n",
    "> the (conditional) probability of $y$ given $x$ is just the (conditional) probability of $x$ given $y$ times the (marginal) probability of $y$ divided by the (marginal) probability of $x$, where the latter is just the integral of the numerator.\n",
    "\n",
    "This is **Bayes' rule**, which itself is not at all controversial, though its application can be as we'll discuss later (Week 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Lego's \n",
    "\n",
    "An example with Lego's (it's awesome):\n",
    "[https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego](https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Monty Hall Problem\n",
    "\n",
    "You are playing a game show and are shown 2 doors.  One has a car behind it, the other a goat.  What are your chances of picking the door with the car?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK, now there are 3 doors: one with a car, two with goats.  The game show host asks you to pick a door, but not to open it yet.  Then the host opens one of the other two doors (that you did not pick), making sure to select one with a goat.  The host offers you the opportunity to switch doors.  Do you?\n",
    " \n",
    " \n",
    "![https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/180px-Monty_open_door.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/180px-Monty_open_door.svg.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now you are back at the 2 door situation.  But what can you make of your prior information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$p(1{\\rm st \\; choice}) = 1/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Try it:\n",
    "https://betterexplained.com/articles/understanding-the-monty-hall-problem/\n",
    "\n",
    "$p({\\rm other}) = 2/3$\n",
    "which doesn't change after host opens door without the prize.\n",
    "So, switching doubles your chances.  But only because you had prior information.  If someone walked in after the \"bad\" door was opened, then their probability of winning is the expected $1/2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "![TextbookGrab1](figures/grab1.tiff)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For $N$ choices, revealing $N-2$ \"answers\" doesn't change the probability of your choice.  It is still $\\frac{1}{N}$.  But it *does* change the probability of your knowledge of the *other* remaining choice by $N-1$ and it is $\\frac{N-1}{N}$. Therefore, by switching, you increase your chance of winning by a factor of (N-1). \n",
    "\n",
    "In the 3-door example, you double your chance of winning (from 1/3 to 2/3). \n",
    "\n",
    "This is an example of the use of *conditional* probability, where we have $p(A|B) \\ne p(A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Contingency Table\n",
    "\n",
    "We can also use Bayes' rule to learn something about false positives and false negatives.\n",
    "\n",
    "Let's say that we have a test for a disease.  The test can be positive ($T=1$) or negative ($T=0$) and one can either have the disease ($D=1$) or not ($D=0$).  So, there are 4 possible combinations:\n",
    "$$T=0; D=0 \\;\\;\\;  {\\rm true \\; negative}$$\n",
    "$$T=0; D=1 \\;\\;\\; {\\rm false \\; negative}$$\n",
    "$$T=1; D=0 \\;\\;\\; {\\rm false \\; positive}$$\n",
    "$$T=1; D=1 \\;\\;\\; {\\rm true \\; positive}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All else being equal, you have a 50% chance of being misdiagnosed.  Not good!  But the probability of disease and the accuracy of the test presumably are not random.\n",
    "\n",
    "If the rates of false positive and false negative are:\n",
    "$$p(T=1|D=0) = \\epsilon_{\\rm FP}$$\n",
    "$$p(T=0|D=1) = \\epsilon_{\\rm FN}$$\n",
    "\n",
    "then the true positive and true negative rates are just:\n",
    "$$p(T=0| D=0) = 1-\\epsilon_{\\rm FP}$$\n",
    "$$p(T=1| D=1) = 1-\\epsilon_{\\rm FN}$$\n",
    "\n",
    "Let's assume that $\\epsilon_{\\rm FP}=0.02$ and $\\epsilon_{\\rm FN}=0.001$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In graphical form this 2x2 p(T=0 or 1|D=0 or 1) matrix is:\n",
    "![http://www.astroml.org/_images/fig_contingency_table_1.png](http://www.astroml.org/_images/fig_contingency_table_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we have a **prior** regarding how likely the disease is, we can take this into account.\n",
    "\n",
    "$$p(D=1)=\\epsilon_D$$\n",
    "\n",
    "and then $p(D=0)=1-\\epsilon_D$. Say, $\\epsilon_D$ = 0.01. \n",
    "\n",
    "Now assume that a person tested positive. What is the probability that this person has the disease? Is it 98% \n",
    "because $\\epsilon_{\\rm FP}=0.02$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can't just read $p(D=1|T=1)$ off the table because the table entry is the conditional probability of the *test* given the *data*, $p(T=1|D=1)$. What we want is the conditional probability of the *data* given the *test*, that is, $p(D=1|T=1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bayes' rule then can be used to help us determine how likely it is \n",
    "that you have the disease if you tested positive:\n",
    "\n",
    "$$p(D=1|T=1) = \\frac{p(T=1|D=1)p(D=1)}{p(T=1)},$$\n",
    "\n",
    "where $$p(T=1) = p(T=1|D=0)p(D=0) + p(T=1|D=1)p(D=1).$$\n",
    "\n",
    "So\n",
    "$$p(D=1|T=1) = \\frac{(1 - \\epsilon_{FN})\\epsilon_D}{\\epsilon_{FP}(1-\\epsilon_D) + (1-\\epsilon_{FN})\\epsilon_D} \\approx \\frac{\\epsilon_D}{\\epsilon_{FP}+\\epsilon_D}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That means that to get a reliable diagnosis, we need $\\epsilon_{FP}$ to be quite small.  (Because you *want* the probability to be close to unity if you test positive, otherwise it is a *false* positive).\n",
    "\n",
    "In our example, we have a disease rate of 1% ($\\epsilon_D = 0.01$) and a false positive rate of 2% ($\\epsilon_{\\rm FP}=0.02$).  \n",
    "\n",
    "So we have\n",
    "$$p(D=1|T=1) = \\frac{0.01}{0.02+0.01} = 0.333$$\n",
    "\n",
    "Then in a sample of, e.g.,  1000 people, 10 people will *actually* have the disease $(1000*0.01)$, but another 20 $(1000*0.02)$ will test positive! \n",
    "\n",
    "Therefore, in that sample of 30 people who tested positive, only 1/3 has the disease\n",
    "(not 98%!). \n",
    "\n",
    "Same math, with often surprising results, applies to DNA tests of murder suspects..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p3.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p4.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p5.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Normal probability density function (pdf): \n",
    "\n",
    "$$p(x|\\mu,\\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(\\frac{-(x-\\mu)^2}{2\\sigma^2}\\right).$$\n",
    "\n",
    "Cumulative distribution function (cdf): \n",
    "\n",
    "$$\\Phi(x|\\mu,\\sigma) = \\int_{-\\infty}^{x}  p(x'|\\mu,\\sigma) dx' $$\n",
    "\n",
    "$$\\Phi(\\infty|\\mu,\\sigma) = 1.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAEJCAYAAACjcV2kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11236de50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's play with Gaussians! Or Normal distributions, N(mu,sigma)\n",
    "## see http://www.astroml.org/book_figures/chapter3/fig_gaussian_distribution.html\n",
    "## Example: IQ is (by definition) distributed as N(mu=100,sigma=15)\n",
    "## Let's plot the IQ distribution first\n",
    "# generate distribution for a grid of x values\n",
    "x = np.linspace(0, 200, 1000)\n",
    "mu=100\n",
    "sigma=15\n",
    "gauss = norm(mu, sigma).pdf(x)  # this is a function of x: gauss(x)\n",
    "# actual plotting\n",
    "fig, ax = plt.subplots(figsize=(5, 3.75))\n",
    "plt.plot(x, gauss, ls='-', c='black', label=r'$\\mu=%i,\\ \\sigma=%i$' % (mu, sigma))\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0, 0.03)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel(r'$p(x|\\mu,\\sigma)$')\n",
    "plt.title('Gaussian Distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00134989803163\n"
     ]
    }
   ],
   "source": [
    "## above we used probability density function (astronomers like to call it \"differential\" df)\n",
    "## the cumulative distribution function, cdf, is the integral of pdf from $x'=-\\infty$ to $x'=x$\n",
    "# What fraction of people have IQ>145?\n",
    "gaussCDF = norm(mu, sigma).cdf(145)\n",
    "print (1-gaussCDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nSigma= 4.75342430882\n",
      "IQ= 171.301364632\n"
     ]
    }
   ],
   "source": [
    "# What IQ corresponds to \"one in a million\"? \n",
    "nSigma = norm.ppf(1-1.0e-6)\n",
    "# norm.ppf returns x for specified cdf, assuming mu=0 and sigma=1 (\"standard normal pdf\")\n",
    "IQ = mu + nSigma*sigma\n",
    "print 'nSigma=',nSigma\n",
    "print 'IQ=', IQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001304\n"
     ]
    }
   ],
   "source": [
    "# let's now look at the same problems using a sample of million points drawn from N(100,15)\n",
    "sampleSize=1000000 \n",
    "gaussSample = norm(mu, sigma).rvs(sampleSize) \n",
    "# What fraction of people have IQ>145?\n",
    "smartOnes = gaussSample[gaussSample>145]\n",
    "print (1.0*np.size(smartOnes)/sampleSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.469483682\n"
     ]
    }
   ],
   "source": [
    "# What IQ corresponds to \"one in a million\"?  \n",
    "print np.max(gaussSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printStats(v):\n",
    "    print 'Size:', np.size(v)\n",
    "    print 'min:', np.min(v)\n",
    "    print 'max:', np.max(v)\n",
    "    print 'mean:', np.mean(v)\n",
    "    print 'median:', np.median(v)\n",
    "    print 'st.dev.:', np.std(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 1000000\n",
      "min: 24.0800924091\n",
      "max: 173.469483682\n",
      "mean: 99.9874849536\n",
      "median: 99.9827489187\n",
      "st.dev.: 15.013898666\n"
     ]
    }
   ],
   "source": [
    "printStats(gaussSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 1304\n",
      "min: 145.003069453\n",
      "max: 173.469483682\n",
      "mean: 149.325446295\n",
      "median: 148.032882171\n",
      "st.dev.: 4.07908002263\n"
     ]
    }
   ],
   "source": [
    "printStats(smartOnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmorons: 26313\n",
      "Nimbecils: 546\n"
     ]
    }
   ],
   "source": [
    "# how many morons in Seattle? IQ in the range 51-70, see\n",
    "# https://en.wikipedia.org/wiki/Moron_(psychology)\n",
    "# we don't expect any idiots in Seattle (IQ<25)\n",
    "## NOTE: this nomenclature was formerly considered a valid descriptor in the psychological \n",
    "##        community, but it is now deprecated in use by psychologists. \n",
    "print 'Nmorons:', np.size(gaussSample[(gaussSample>50) & (gaussSample<71)])\n",
    "print 'Nimbecils:', np.size(gaussSample[(gaussSample>26) & (gaussSample<51)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian confidence levels\n",
    "\n",
    "The probability of a measurement drawn from a Gaussian distribution that is between $\\mu-a$ and $\\mu+b$ is\n",
    "$$\\int_{\\mu-a}^{\\mu+b} p(x|\\mu,\\sigma) dx.$$\n",
    "\n",
    "For $a=b=1\\sigma$, we get the familar result of 68.3%.  For $a=b=2\\sigma$ it is 95.4%.  So we refer to the range $\\mu \\pm 1\\sigma$ and $\\mu \\pm 2\\sigma$ as the 68% and 95% **confidence limits**, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## now let's go back to the problem of estimating location and scale\n",
    "## given a sample, such as gaussSample above, how do we estimate its mu and sigma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sample vs. Population Statistics \n",
    "\n",
    "Statistics estimated from the *data* are called _sample statistics_ as compared to _population statistics_ which come from knowing the functional form of the pdf. For example, the expectation value for a known h(x) is\n",
    "\n",
    "$$\\mu \\equiv E(x) = \\int_{-\\infty}^{\\infty} x h(x) dx,$$\n",
    "\n",
    "where $h(x)$ must be properly normalized (the integral gets replaced by a sum for discrete distributions).\n",
    "\n",
    "E(x) is the expecation value of $x$.  If you want the expectation value of something else--say $x^2$ or $(x-\\mu)^2$, you replace $x$ with that. Importantly, the *variance* is the expectation value of $(x-\\mu)^2$\n",
    "\n",
    "$$\\sigma^2 \\equiv V = \\int_{-\\infty}^{\\infty}  (x-\\mu)^2 h(x) dx,$$\n",
    "\n",
    "where, again, the integral gets replaced by a sum for discrete distributions.\n",
    "\n",
    "Specifically, $\\mu$ is the *population average*, i.e., it is the expecation value of $x$ for $h(x)$.  But we don't *know* $h(x)$.  \n",
    "\n",
    "So the **sample mean**, $\\overline{x}$, is an *estimator* of $\\mu$, defined as\n",
    "$$\\overline{x} \\equiv \\frac{1}{N}\\sum_{i=1}^N x_i,$$\n",
    "which we determine from the data itself.  Similarly, the **sample variance** ($s^2$, where \n",
    "$s$ is the sample standard deviation) is an *estimator* of $\\sigma^2$:\n",
    "$$s^2 \\equiv \\frac{1}{N-1}\\sum_{i=1}^N (x_i-\\overline{x})^2.$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sample vs. Population Statistics \n",
    "\n",
    "The **sample variance** ($s^2$, where \n",
    "$s$ is the sample standard deviation) is an *estimator* of $\\sigma^2$:\n",
    "$$s^2 \\equiv \\frac{1}{N-1}\\sum_{i=1}^N (x_i-\\overline{x})^2.$$\n",
    "\n",
    "**WAIT!!!** Why do we have (N-1) and not N (as in expression for the mean)???\n",
    "\n",
    "The reason for the (N-1) term instead of the naively expected N in the second expression is related to the fact that $\\overline{x}$ is also determined from data (we will discuss this subtle fact and the underlying statistical justification for the (N-1) term in more detail in Week 4 lectures. With N replaced by (N-1) (the so-called Bessel’s correction), the sample variance (i.e., $\\sigma^2$) becomes unbiased (and the sample standard deviation becomes a less biased, but on average still underestimated, estimator of the true standard deviation). \n",
    "\n",
    "What does \"biased\" mean? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p13.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p11.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p12.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p8.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Anscombe's quartet comprises four datasets that have nearly identical simple descriptive statistics, yet appear very different when graphed. \n",
    "\n",
    "![SlideGrab](figures/AnscombeQuartet.tiff)\n",
    "\n",
    "![SlideGrab](figures/AnscombeQuartetTable.tiff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
